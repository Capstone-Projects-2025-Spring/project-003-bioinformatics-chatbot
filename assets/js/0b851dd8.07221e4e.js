"use strict";(self.webpackChunkcreate_project_docs=self.webpackChunkcreate_project_docs||[]).push([[6155],{70692:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>o,default:()=>l,frontMatter:()=>s,metadata:()=>a,toc:()=>c});var i=n(74848),r=n(28453);const s={sidebar_position:4},o="Algorithm Description",a={id:"system-architecture/Algorithm_Design",title:"Algorithm Description",description:"This document is a summary of the algorithms used in the project",source:"@site/docs/system-architecture/Algorithm_Design.md",sourceDirName:"system-architecture",slug:"/system-architecture/Algorithm_Design",permalink:"/project-003-bioinformatics-chatbot/docs/system-architecture/Algorithm_Design",draft:!1,unlisted:!1,editUrl:"https://github.com/Capstone-Projects-2025-Spring/project-003-bioinformatics-chatbot/edit/main/documentation/docs/system-architecture/Algorithm_Design.md",tags:[],version:"current",lastUpdatedBy:"JustinTruong456",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"docsSidebar",previous:{title:"Sequence Diagrams",permalink:"/project-003-bioinformatics-chatbot/docs/system-architecture/Sequence Diagram"},next:{title:"Database Design",permalink:"/project-003-bioinformatics-chatbot/docs/system-architecture/Database-Design"}},d={},c=[{value:"Indexing",id:"indexing",level:2},{value:"Query Translation",id:"query-translation",level:2},{value:"Retrieval Augmented Generation (RAG)",id:"retrieval-augmented-generation-rag",level:2},{value:"Retrieval",id:"retrieval",level:3},{value:"Augmentation",id:"augmentation",level:3},{value:"Generation",id:"generation",level:3}];function h(e){const t={em:"em",h1:"h1",h2:"h2",h3:"h3",p:"p",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h1,{id:"algorithm-description",children:"Algorithm Description"}),"\n",(0,i.jsx)(t.p,{children:"This document is a summary of the algorithms used in the project"}),"\n",(0,i.jsx)(t.h2,{id:"indexing",children:"Indexing"}),"\n",(0,i.jsx)(t.p,{children:"In order to turn the documents from stakeholders into useable information for\nanswering questions and creating tutorials, there needs to be a way to properly parse these documents."}),"\n",(0,i.jsxs)(t.p,{children:["One of the most popular, and powerful, methods of transforming documents\ninto searchable objects by content is known as ",(0,i.jsx)(t.em,{children:"Semantic Embedding"}),"."]}),"\n",(0,i.jsx)(t.p,{children:"Semantic Embedding is achieved by chunking documents, tokenizing words and placing\nthem into a vector-space. In order to transform the chunk of tokens into a vector space\nan embedding model is used, i our case the pre trained embedding model used is mxbai-embed-large.\nOnce the chunks of data are send through the embedding model and vectorized the vectors are  saved\nand stored in Langchain's created PGVector table on our database. Semantic embedding allows for\nuseful searches as each document has a unique space on the vector-space, allowing for complex queries\ncontaining synonyms to retrieve documents."}),"\n",(0,i.jsx)(t.h2,{id:"query-translation",children:"Query Translation"}),"\n",(0,i.jsx)(t.p,{children:"In order to meaningfully map a user's input to the indexed documents,\nor knowledge base, some form of query translation has to occur. The general\nsteps for this include tokenization and vectorization."}),"\n",(0,i.jsx)(t.p,{children:"In a similar fashion to document tokenization,\nthe user's query has to be tokenized and then ran through the embedding model which will\nvectorize the query much like the documents."}),"\n",(0,i.jsx)(t.p,{children:"Once the query is translated, it will be used to retrieve the most relevant documents."}),"\n",(0,i.jsx)(t.h2,{id:"retrieval-augmented-generation-rag",children:"Retrieval Augmented Generation (RAG)"}),"\n",(0,i.jsx)(t.h3,{id:"retrieval",children:"Retrieval"}),"\n",(0,i.jsx)(t.p,{children:"Retrieval uses the indexed documents described previously as a knowledge base.\nThe translated query will then be compared against the indexed documents using a retrieval method."}),"\n",(0,i.jsx)(t.h3,{id:"augmentation",children:"Augmentation"}),"\n",(0,i.jsx)(t.p,{children:"Once the correct documents are chosen out of the indexed knowledge base,\nthey need to be prepared for the generation phase."}),"\n",(0,i.jsx)(t.p,{children:"Augmentation is done during the indexing phase of the document as it is split into chunks which are\nstored in the database."}),"\n",(0,i.jsx)(t.h3,{id:"generation",children:"Generation"}),"\n",(0,i.jsx)(t.p,{children:"The last step of the RAG process and algorithms is generation via LLM.\nThe retrieved and augmented documents, as well as any other context\n(In this case, the initial user query) are passed to a language model\nsuch as ChatGPT, Gemini, or something else."}),"\n",(0,i.jsx)(t.p,{children:"This last step translates the given context, and items from the knowledge\nbase, into useable answers and context for users."})]})}function l(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>a});var i=n(96540);const r={},s=i.createContext(r);function o(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);